## Barcelona Smart Drone Challenge

BSDC 2020 engages undergraduate teams throughout the globe in designing, constructing, developing and demonstrating an autonomous unmanned aircraft system. It is capable of performing a series of tasks which include area search, waypoint navigation, capturing data and photographs of the area, dropping payloads at certain places on the ground, performing manoeuvres like touch-and-go, and finally return to the base through a defined route. With a Maximum Take-off Mass (MTOM) of under 7 kg, and operating within Visual Line of Sight (VLOS), the unmanned aircraft is visioned to be used in case of natural calamities.

<div class="image-1">
<content-image src="robots/parachute-test-1.jpg" alt="Drone" ></content-image>
</div>

Participating for the first time in the Barcelona Smart Drone Challenge (BSDC) in its 2020 edition, the team AeRoVe has been working towards autonomous fixed-wing vehicles since December 2019. After successfully completing the two (“Concept Review” and “Preliminary Design Review”) out of the three review rounds (required to be completed before participating in the final competition in Barcelona), the team is continuously adding to develop a rigorous system of autonomous fixed-wing aerial vehicles. Since then, the team has built over ten prototypes and test aerial vehicles, and have successfully flown these vehicles to study and improve the operations of the system. The team was preparing to complete the last round (“Flight Readiness Review”) required to be completed before the actual competition in Barcelona, but the subsequent events and the competition were detained on account of the COVID-19 pandemic.

<div class="image-1">
<content-image src="robots/jatayu-1.jpg" alt="Drone" ></content-image>
</div>

The team has built and tested different designs of fixed-wing vehicles for their control response and capability of flying with heavyweights on board. All the vehicles are installed with ProfiCNC’s PixHawk Cube as the flight controller and a GPS module from u-blox to guide the drone through different GPS coordinates to complete the mission. Since the mission requires detection of alpha-numerical characters on the ground, a camera is needed to be installed on the vehicle which can detect the image and send it to a computer which then uses ‘Perception’ and ‘Machine Learning’ algorithms to extract the information or the text written on the ground. This data is used by the ‘Controls’ to determine the next manoeuvre of the vehicle according to the mission statement. We are currently working on the ‘remotely’ governable aspects of the mission and flight. The team is also testing the ‘Machine Learning’, ‘Controls’ and ‘Perception’ algorithms for different scenarios, while also improving the design of the vehicle in the ‘Mechatronics’ subsystems by studying the various forces and moments acting on the airframe in a flight.

Future hardware testing will begin as soon as the COVID19 conditions improve in the country.
